{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np  # linear algebra\n",
    "import pandas as pd  # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA, TruncatedSVD\n",
    "import matplotlib.patches as mpatches\n",
    "import time\n",
    "\n",
    "# Classifier Libraries\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import collections\n",
    "\n",
    "\n",
    "# Other Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from imblearn.pipeline import make_pipeline as imbalanced_make_pipeline\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import NearMiss\n",
    "from imblearn.metrics import classification_report_imbalanced\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score, roc_auc_score, accuracy_score, classification_report\n",
    "from collections import Counter\n",
    "from sklearn.model_selection import KFold, StratifiedKFold\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"creditcard.csv\", low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_count_with_percentage(column: pd.Series):\n",
    "    count_dict = column.value_counts().to_dict()\n",
    "    for label in count_dict:\n",
    "        count = count_dict[label]\n",
    "        percentage = round((count/len(column))*100, 4)\n",
    "        print(f\"{label} = {count} ({percentage}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count_with_percentage(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='Class', data=df)\n",
    "plt.title('Class Distributions \\n (0: No Fraud || 1: Fraud)', fontsize=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "import random\n",
    "import math\n",
    "\n",
    "\n",
    "def plot_distributions(column_list: List[str], df: pd.DataFrame):\n",
    "    col_count = len(column_list)\n",
    "    row_count = col_count//2\n",
    "    row_count = 1 if not row_count else row_count\n",
    "    col_count = len(column_list)\n",
    "    fig, ax = plt.subplots(row_count, 2, figsize=(15, 15))\n",
    "    palettes = sns.color_palette()\n",
    "    row_num = 0\n",
    "    fig_no = 0\n",
    "    for index, column in enumerate(column_list):\n",
    "        column_val = df[column].values\n",
    "        # Choose a random color palette from the list\n",
    "        random_palette = random.choice(palettes)\n",
    "        fig_no += 1\n",
    "        sns.distplot(column_val, ax=ax[row_num,\n",
    "                     index % 2], color=random_palette)\n",
    "        ax[row_num, index % 2].set_title(\n",
    "            f'Distribution of {column}', fontsize=14)\n",
    "        ax[row_num, index % 2].set_xlim([min(column_val), max(column_val)])\n",
    "        if fig_no % 2 == 0:\n",
    "            row_num += 1\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_distributions([\"Amount\", \"V1\", \"Time\", \"V2\"], df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scale Time and Amount feature as other features are already scaled "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking for outlires as it will help us to choose the scaler\n",
    "\n",
    "def detect_outliers_iqr(column: pd.Series):\n",
    "    # Calculate the 25th and 75th percentiles\n",
    "    q1 = np.percentile(column, 25)\n",
    "    q3 = np.percentile(column, 75)\n",
    "\n",
    "    # Calculate the IQR (Interquartile Range)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Define the lower and upper bounds for outliers\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    # Identify outliers using the bounds\n",
    "    outliers = column[(column < lower_bound) | (column > upper_bound)]\n",
    "\n",
    "    return outliers\n",
    "\n",
    "\n",
    "print(\"Number of Outlires in Time = \", len(detect_outliers_iqr(df.Time)))\n",
    "print(\"Number of Outlires in Amount = \", len(detect_outliers_iqr(df.Amount)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking outlires with box plot\n",
    "sns.boxplot(x=df.Time, orient=\"v\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.boxplot(y=df.Amount)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.stripplot(data=df,\n",
    "              x=\"Amount\",      # x axis column from data\n",
    "              y=None,      # y axis column from data\n",
    "              color=\"crimson\",  # Colours the dots\n",
    "              linewidth=1,     # Dot outline width\n",
    "              alpha=0.4)       # Makes them transparent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "# as there is a presence of outlires we are using robus scaler\n",
    "scaler = RobustScaler()\n",
    "\n",
    "df['Amount'] = scaler.fit_transform(df[['Amount']]).flatten()\n",
    "df['Time'] = scaler.fit_transform(df[['Time']]).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data set\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "You can choose any integer value for random_state, and as long as you use the same value,\n",
    "you will always get the same split. If you don't specify a random_state value, the split will still be random,\n",
    "but it will vary each time you run the function.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "X = df.drop('Class', axis=1)\n",
    "y = df['Class']\n",
    "original_Xtest, original_Xtrain, original_ytest, original_ytrain = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# we are splitting the data set before Under Scaling to have the test data from the original dataset\n",
    "\n",
    "# now we will under smaple the test data and train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count_with_percentage(original_ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count_with_percentage(original_ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = original_Xtest\n",
    "train_df[\"Class\"] = original_ytest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fraud_df = train_df[train_df.Class == 1]\n",
    "len(fraud_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_fraud_df = train_df[train_df.Class == 0]\n",
    "len(non_fraud_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "under_smpled_df = pd.concat([fraud_df, non_fraud_df[:len(fraud_df)]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_count_with_percentage(under_smpled_df.Class)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploring correlation of out under sampled dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_data = round(under_smpled_df.corr(), 2)\n",
    "fig, ax = plt.subplots(figsize=(20, 8))\n",
    "sns.heatmap(corr_data, cmap='coolwarm_r', ax=ax, annot=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_strong_correlations(df, target_column, threshold=0.4):\n",
    "    # Compute the correlation matrix\n",
    "    corr_matrix = df.corr()\n",
    "    positive_corr_cols = []\n",
    "    negative_corr_cols = []\n",
    "    for col in df.columns:\n",
    "        if col != target_column:\n",
    "            score = corr_matrix[target_column][col]\n",
    "            # print(score)\n",
    "            if score >= threshold:\n",
    "                print(\"Strong positive Correlation--->\", col, \" = \", score)\n",
    "                positive_corr_cols.append(col)\n",
    "            elif score <= -threshold:\n",
    "                print(\"Strong negative Correlation--->\", col, \" = \", score)\n",
    "                negative_corr_cols.append(col)\n",
    "\n",
    "    return positive_corr_cols, negative_corr_cols\n",
    "\n",
    "\n",
    "positive, negative = find_strong_correlations(under_smpled_df, \"Class\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_plot_corr(df: pd.DataFrame, col_list: List[str], label_name: str):\n",
    "    for col in col_list:\n",
    "        f, ax = plt.subplots(1, 1, figsize=(12, 4))\n",
    "        sns.boxplot(x=label_name, y=col, data=df, ax=ax)\n",
    "        plt.show()\n",
    "\n",
    "# box_plot_corr(under_smpled_df,negative,\"Class\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "X = under_smpled_df.drop('Class', axis=1)\n",
    "y = under_smpled_df.Class\n",
    "importances = mutual_info_classif(X, y)\n",
    "feat_importance = pd.Series(importances, under_smpled_df.columns[:-1])\n",
    "feat_importance.plot(kind='barh', color='teal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns[:-1]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
